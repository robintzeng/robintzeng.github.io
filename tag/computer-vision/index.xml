<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computer Vision | JING AN TZENG</title>
    <link>https://robintzeng.github.io/tag/computer-vision/</link>
      <atom:link href="https://robintzeng.github.io/tag/computer-vision/index.xml" rel="self" type="application/rss+xml" />
    <description>Computer Vision</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 27 Mar 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://robintzeng.github.io/images/icon_hu33e8c61f27fd641c1e5b23db9d65383a_5197_512x512_fill_lanczos_center_2.png</url>
      <title>Computer Vision</title>
      <link>https://robintzeng.github.io/tag/computer-vision/</link>
    </image>
    
    <item>
      <title>Depth Completion</title>
      <link>https://robintzeng.github.io/project/cv/</link>
      <pubDate>Fri, 27 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://robintzeng.github.io/project/cv/</guid>
      <description>




  











&lt;figure id=&#34;figure-fig-1-two-pathway&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/model.png&#34; data-caption=&#34;Fig. 1 Two Pathway&#34;&gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/model.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Fig. 1 Two Pathway
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We develop the learning architecture that can effectively complete the dense depth from a &lt;strong&gt;color image&lt;/strong&gt; and &lt;strong&gt;sparse LiDAR&lt;/strong&gt; data.&lt;/p&gt;
&lt;p&gt;Our model consists of two pathways: the &lt;strong&gt;local pathway&lt;/strong&gt; and the &lt;strong&gt;global pathway&lt;/strong&gt; which is illustrated in Fig 1. The local pathway aims to extract high-resolution features, and it is made up of 2D blocks, which is illustrated in Fig. 2(b). The global pathway extracts low-resolution features, and it comprises our proposed U-Block, as shown in Fig. 2(a). The structure of the pathway is illustrated in Fig 3.&lt;/p&gt;
&lt;p&gt;Also, we improve the performance of the local pathway by concatenating binary mask to the sparse LiDAR data, because the binary mask can help our model to indicate the valid values of sparse LiDAR data.&lt;/p&gt;
&lt;p&gt;Finally, to combine the results of the local and global pathways, we apply the attention mechanism (confidence map) to integrate the predicted dense from two pathways.&lt;/p&gt;





  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/block.png&#34; &gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/block.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;






  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/pathway_struct.png&#34; &gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/pathway_struct.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;






  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/confidence.png&#34; &gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/confidence.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;






  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/performance.png&#34; &gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/performance.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

</description>
    </item>
    
    <item>
      <title>Visual Inertia Navigation</title>
      <link>https://robintzeng.github.io/project/mobile/</link>
      <pubDate>Fri, 27 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://robintzeng.github.io/project/mobile/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;This project aims to adopt an open-source visual
inertial navigation framework with two modifications. First, an
alternative visual descriptor and extractor, SuperPoint, is tested
in place of ORB features. Secondly, an invariant error state is
implemented in order to more effectively track the IMU pose
uncertainty while maintaining the visual feature correction step
in a ”dual track” system. Each of these changes is evaluated
separately on three datasets obtained from the 
&lt;a href=&#34;https://projects.asl.ethz.ch/datasets/doku.php?id=kmavvisualinertialdatasets&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;EuRoC MAV
dataset&lt;/a&gt;. Our code repository is located 
&lt;a href=&#34;https://github.com/robintzeng/EECS568_team_14_open_vins&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;performance&#34;&gt;Performance&lt;/h2&gt;
&lt;p&gt;Evaluate the performance on the EuRoC  MAV dataset





  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/Traj.png&#34; &gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/Traj.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;br&gt;





  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/Table_RMSE.png&#34; &gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/Table_RMSE.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;br&gt;





  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/Error_med.png&#34; &gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/Error_med.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;






  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/Error_diff.png&#34; &gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/Error_diff.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;






  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/Table_Time.png&#34; &gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/Table_Time.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/RPiYuu_pLAU&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
  </channel>
</rss>
