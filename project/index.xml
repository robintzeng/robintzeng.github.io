<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | </title>
    <link>https://robintzeng.github.io/project/</link>
      <atom:link href="https://robintzeng.github.io/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 27 Mar 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://robintzeng.github.io/images/icon_hu33e8c61f27fd641c1e5b23db9d65383a_5197_512x512_fill_lanczos_center_2.png</url>
      <title>Projects</title>
      <link>https://robintzeng.github.io/project/</link>
    </image>
    
    <item>
      <title>Depth Completion</title>
      <link>https://robintzeng.github.io/project/cv/</link>
      <pubDate>Fri, 27 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://robintzeng.github.io/project/cv/</guid>
      <description>




  











&lt;figure id=&#34;figure-fig-1-two-pathway&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/model.png&#34; data-caption=&#34;Fig. 1 Two Pathway&#34;&gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/model.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Fig. 1 Two Pathway
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;We develop the learning architecture that can effectively complete the depth from a &lt;strong&gt;color image&lt;/strong&gt; and &lt;strong&gt;sparse LiDAR&lt;/strong&gt; data.&lt;br&gt; Our model consists of two
pathways: the local pathway and the global pathway which is illustrated in Fig 1.&lt;br&gt;
The local pathway aims to extract high-resolution features, and it is made up of 2D block, which is illustrated in Fig. 2(b). The global pathway extracts low-resolution features, and it comprises our proposed U-Block, as shown in Fig. 2(a). Also, we improve the
performance of the local pathway by concatenating binary
mask to the sparse LiDAR data, because the binary mask
can help our model to indicate the valid values of sparse LiDAR data. Finally, to combine the results of the local and
global pathways, we apply the attention mechanism(confidence map) to integrate the predicted dense from two pathways.&lt;/p&gt;





  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/block.png&#34; &gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/block.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;






  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/pathway_struct.png&#34; &gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/pathway_struct.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;






  











&lt;figure &gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/confidence.png&#34; &gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/confidence.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;



&lt;/figure&gt;

</description>
    </item>
    
    <item>
      <title>Eurobot 2018</title>
      <link>https://robintzeng.github.io/project/eurobot/</link>
      <pubDate>Sun, 27 May 2018 00:00:00 +0000</pubDate>
      <guid>https://robintzeng.github.io/project/eurobot/</guid>
      <description>




  











&lt;figure id=&#34;figure-robots&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/robot.JPG&#34; data-caption=&#34;Robots&#34;&gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/robot.JPG&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Robots
  &lt;/figcaption&gt;


&lt;/figure&gt;






  











&lt;figure id=&#34;figure-map&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/map.png&#34; data-caption=&#34;Map&#34;&gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/map.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Map
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;conteset&#34;&gt;Conteset&lt;/h2&gt;
&lt;p&gt;For each team, we have to make two robots that can cooperate to finish the tasks on the given map such as throwing the ball into a bucket and stacking the color bricks in the given order.&lt;br&gt;&lt;/p&gt;
&lt;p&gt;When the robots finish the task, they would get some points. The team with higher scores wins.&lt;/p&gt;
&lt;p&gt;I was the software team leader in this contest. In our team, we took charge of sensing the world and making the decision for the robot. In addition, I also made an indoor positioning system with UWB and Kalman filter which can locate the rival accurately.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/Uo4OeNeYvSM&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Exoskeleton</title>
      <link>https://robintzeng.github.io/project/exo/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://robintzeng.github.io/project/exo/</guid>
      <description>




  











&lt;figure id=&#34;figure-robots&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/robot.JPG&#34; data-caption=&#34;Robots&#34;&gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/robot.JPG&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Robots
  &lt;/figcaption&gt;


&lt;/figure&gt;






  











&lt;figure id=&#34;figure-map&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/map.png&#34; data-caption=&#34;Map&#34;&gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/map.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Map
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/Uo4OeNeYvSM&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Mobile Robotics</title>
      <link>https://robintzeng.github.io/project/mobile/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://robintzeng.github.io/project/mobile/</guid>
      <description>




  











&lt;figure id=&#34;figure-robots&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/robot.JPG&#34; data-caption=&#34;Robots&#34;&gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/robot.JPG&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Robots
  &lt;/figcaption&gt;


&lt;/figure&gt;






  











&lt;figure id=&#34;figure-map&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://robintzeng.github.io/img/map.png&#34; data-caption=&#34;Map&#34;&gt;


  &lt;img src=&#34;https://robintzeng.github.io/img/map.png&#34; alt=&#34;&#34;  &gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Map
  &lt;/figcaption&gt;


&lt;/figure&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/Uo4OeNeYvSM&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
  </channel>
</rss>
